import os, argparse, logging, sys
sys.path.append("..")

import torch
import numpy as np
from torch.utils.data import DataLoader, Subset, random_split
from torchvision import transforms
import random
from processor.dataset import LEDProcessor, LEDDataset
from models.bert_model import HMNeTNERModel
from models.unimo_model import UnimoCRFModel
from models.mtl_ddpm_model import DiffusionModel
from modules.ddpm_train import PreTrainer

logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',
                    datefmt = '%m/%d/%Y %H:%M:%S',
                    level = logging.INFO)
logger = logging.getLogger(__name__)

MODEL_CLASSES = {
    #'twitter15': HMNeTNERModel,
    'twitter15': UnimoCRFModel,
    'twitter17': HMNeTNERModel
}

TRAINER_CLASSES = {
    'twitter15': PreTrainer,
    'twitter17': PreTrainer
}

DATA_PROCESS = {
    'twitter15': (LEDProcessor, LEDDataset), 
    'twitter17': (LEDProcessor, LEDDataset)
}

DATA_PATH = {
    'twitter15': {
                'train': 'data/NER_data/twitter2015/train.txt',
                'dev': 'data/NER_data/twitter2015/valid.txt',
                'test': 'data/NER_data/twitter2015/test.txt',
                'predict': 'data/NER_data/twitter2015/unlabeled.txt',
                'supervised': 'data/NER_data/twitter2015/labeled.txt',
                'auximgs': 'data/NER_data/twitter2015/twitter2015_aux_dict.pth',
                'img2crop': 'data/NER_data/twitter15_detect/twitter15_img2crop.pth'
            },

    'twitter17': {
                'train': 'data/NER_data/twitter2017/train.txt',
                'dev': 'data/NER_data/twitter2017/valid.txt',
                'test': 'data/NER_data/twitter2017/test.txt',
                'predict': 'data/NER_data/twitter2017/unlabeled.txt',
                'supervised': 'data/NER_data/twitter2017/labeled.txt',
                'auximgs': 'data/NER_data/twitter2017/twitter2017_aux_dict.pth',
                'img2crop': 'data/NER_data/twitter17_detect/twitter17_img2crop.pth'
            }     
}

# image data
IMG_PATH = {
    'twitter15': 'data/NER_data/twitter2015_images',
    'twitter17': 'data/NER_data/twitter2017_images'
}

# auxiliary images
AUX_PATH = {
    'twitter15': 'data/NER_data/twitter2015_aux_images/crops',
    'twitter17': 'data/NER_data/twitter2017_aux_images/crops'
}

# char lstm vocab and pre-trained parameters
CLSTM_PATH = {
    'twitter15': 'char_lstm/twitter2015',
    'twitter17': 'char_lstm/twitter2017'
}

def set_seed(seed=2021):
    """set random seed"""
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    np.random.seed(seed)
    random.seed(seed)

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--dataset_name", default="twitter15", type=str, help="The name of dataset.")
    parser.add_argument("--ner_model_name", default="hvpnet", type=str, help="The name of supporting NER model.")
    parser.add_argument('--vit_name', default='vit', type=str, help="The name of vit.")
    parser.add_argument('--num_epochs', default=20, type=int, help="num training epochs")
    parser.add_argument('--device', default='cuda', type=str, help="cuda or cpu")
    parser.add_argument('--batch_size', default=32, type=int, help="batch size")
    parser.add_argument('--lr', default=1e-5, type=float, help="learning rate")
    parser.add_argument('--warmup_ratio', default=0.01, type=float)
    parser.add_argument('--eval_begin_epoch', default=16, type=int, help="epoch to start evluate")
    parser.add_argument('--seed', default=1, type=int, help="random seed, default is 1")
    parser.add_argument("--local_cache_path", default="/home/yixin/workspace/huggingface/", type=str, help="The path to the local repository of HuggingFace models.")
    parser.add_argument("--lm_name", default="bert-base-uncased", type=str, help="Pretrained language model")
    parser.add_argument("--char_hidden_dim", default=512, type=int, help="The dimension of the hidden embeddings generated by the Character-level LSTM.")
    parser.add_argument('--label_hidden_dim', default=256, type=int, help="The hidden dimensions of label features.")
    parser.add_argument('--time_hidden_dim', default=128, type=int, help="The hidden dimensions of time.")
    parser.add_argument('--prompt_len', default=10, type=int, help="prompt length")
    parser.add_argument('--prompt_dim', default=800, type=int, help="mid dimension of prompt project layer")
    parser.add_argument('--noise_dim', default=128, type=int, help="The dimensions of noises")
    parser.add_argument('--load_path', default=None, type=str, help="Load model from load_path")
    parser.add_argument('--save_path', default=None, type=str, help="save model at save_path")
    parser.add_argument('--notes', default="", type=str, help="input some remarks for making save path dir.")
    parser.add_argument('--do_pretrain', action='store_true')
    parser.add_argument('--do_train', action='store_true')
    parser.add_argument('--do_adv_train', action='store_true')
    parser.add_argument('--predict', action='store_true')
    parser.add_argument("--max_seq_len", default=128, type=int)
    parser.add_argument("--max_char_len", default=128, type=int)
    parser.add_argument('--use_prompt', action='store_true')
    parser.add_argument('--crf_lr', default=5e-2, type=float, help="learning rate")
    parser.add_argument('--prompt_lr', default=3e-4, type=float, help="learning rate")
    parser.add_argument('--aux_size', default=128, type=int, help="batch size")
    parser.add_argument('--rcnn_size', default=64, type=int, help="batch size")
    parser.add_argument('--folds',default=5, type=int, help="The number of folds for cross validation.")
    parser.add_argument('--lambda_id', default=1.0, type=float, help="The hyperparameter to control the impact of the identity loss.")
    parser.add_argument('--lambda_edit', default=1.0, type=float, help="The hyperparameter to control the impact of the edit loss.")
    parser.add_argument('--lambda_cycle', default=1.0, type=float, help="The hyperparameter to control the impact of the cycle loss.")
    parser.add_argument('--lambda_contrast', default=1.0, type=float, help="The hyperparameter to control the impact of the contrastive loss.")
    parser.add_argument('--train_steps', default=1000, type=int, help="The number of timesteps for training a diffusion model.")
    parser.add_argument('--eva_steps', default=10, type=int, help="The number of timesteps for inference with a diffusion model.")

    args = parser.parse_args()

    data_path, imgs_path, aux_imgs_path, clstm_path = DATA_PATH[args.dataset_name], IMG_PATH[args.dataset_name], AUX_PATH[args.dataset_name], CLSTM_PATH[args.dataset_name]
    model_class, Trainer = MODEL_CLASSES[args.dataset_name], TRAINER_CLASSES[args.dataset_name]
    data_process, dataset_class = DATA_PROCESS[args.dataset_name]
    rcnn_imgs_path = "data/NER_data"

    transform = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])])
    
    set_seed(args.seed) # set seed, default is 1
    if args.save_path is not None:  # make save_path dir
        if not os.path.exists(args.save_path):
            os.makedirs(args.save_path, exist_ok=True)
    print(args)
    logdir = "logs/" + args.dataset_name+ "_"+str(args.batch_size) + "_" + str(args.lr) + args.notes
    writer=None

    if not args.use_prompt:
        imgs_path, aux_imgs_path = None, None

    processor = data_process(data_path, clstm_path, args)

    unlabeled_dataset = dataset_class(processor, transform, imgs_path, aux_imgs_path, args.max_seq_len, args.max_char_len, mode="predict", aux_size=args.aux_size, rcnn_imgs_path=rcnn_imgs_path, rcnn_size=args.rcnn_size)
    train_sz, val_sz = int(0.6*len(unlabeled_dataset)), int(0.05*len(unlabeled_dataset))
    unlabeled_all_indices = list(range(len(unlabeled_dataset)))
    random.shuffle(unlabeled_all_indices)
    train_unlabeled_indices = unlabeled_all_indices[:train_sz]
    val_unlabeled_indices = unlabeled_all_indices[train_sz:train_sz+val_sz]
    test_unlabeled_indices = unlabeled_all_indices[train_sz+val_sz:]
    train_dataset_unlabeled = unlabeled_dataset.from_indices(train_unlabeled_indices)
    val_dataset_unlabeled = unlabeled_dataset.from_indices(val_unlabeled_indices)
    test_dataset_unlabeled = unlabeled_dataset.from_indices(test_unlabeled_indices)
    train_dataloader_unlabeled = DataLoader(train_dataset_unlabeled, batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True)
    val_dataloader_unlabeled = DataLoader(val_dataset_unlabeled, batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True)
    test_dataloader_unlabeled = DataLoader(test_dataset_unlabeled, batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True)

    labeled_dataset = dataset_class(processor, transform, imgs_path, aux_imgs_path, args.max_seq_len, args.max_char_len, mode="supervised", aux_size=args.aux_size, rcnn_imgs_path=rcnn_imgs_path, rcnn_size=args.rcnn_size)
    train_sz, val_sz = int(0.6*len(labeled_dataset)), int(0.1*len(labeled_dataset))
    labeled_all_indices = list(range(len(labeled_dataset)))
    random.shuffle(labeled_all_indices)
    train_labeled_indices = labeled_all_indices[:train_sz]
    val_labeled_indices = labeled_all_indices[train_sz:train_sz+val_sz]
    test_labeled_indices = labeled_all_indices[train_sz+val_sz:]
    train_dataset_labeled = labeled_dataset.from_indices(train_labeled_indices)
    val_dataset_labeled = labeled_dataset.from_indices(val_labeled_indices)
    test_dataset_labeled = labeled_dataset.from_indices(test_labeled_indices)
    train_dataloader_labeled = DataLoader(train_dataset_labeled, batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True)
    val_dataloader_labeled = DataLoader(val_dataset_labeled, batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True)
    test_dataloader_labeled = DataLoader(test_dataset_labeled, batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True)

    label_mapping = processor.get_label_mapping()
    label_embeddings = processor.get_label_embedding()
    label_list = list(label_mapping.keys())
    
    if args.do_pretrain:
        if args.ner_model_name == "hvpnet":
            ner_model = HMNeTNERModel(len(label_list), args).to(args.device)
        elif args.ner_model_name == "mkgformer":
            ner_model = UnimoCRFModel(len(label_list), args).to(args.device)
        else:
            ner_model = None
        forward_net = DiffusionModel(args, len(label_list), clstm_path, ner_model_name="mkgformer", vt_model_dir="new").to(args.device)
        trainer = PreTrainer(train_data=train_dataloader_unlabeled, val_data=val_dataloader_unlabeled, test_data=test_dataloader_unlabeled, ner_model=ner_model, ner_model_name=args.ner_model_name,
                      forward_net=forward_net, label_map=label_mapping, args=args, logger=logger, writer=writer)
        trainer.train()
        args.load_path = os.path.join(args.save_path, "best_model")
        trainer.test()
        os.rename("best_model.pth", "hvpnet.pth")
    
    if args.do_adv_train:
        forward_net = DiffusionModel(args, len(label_list), clstm_path, ner_model_name="mkgformer", vt_model_dir="new")
        forward_net.to(args.device)
        reverse_net = DiffusionModel(args, len(label_list), clstm_path, ner_model_name="mkgformer", vt_model_dir="old")
        reverse_net.to(args.device)
        ddpm_trainer = DDPMTrainer(train_data=train_dataloader_labeled, val_data=val_dataloader_labeled, test_data=test_dataloader_labeled, unlabeled_data=val_dataloader_unlabeled, 
                                         forward_net=forward_net, reverse_net=reverse_net, label_map=label_mapping, args=args, logger=logger, writer=writer)
        args.load_path = os.path.join(args.save_path, "best_")
        ddpm_trainer.train()
        ddpm_trainer.test()

    if args.predict:
        forward_net = DiffusionModel(args, len(label_list), clstm_path, ner_model_name="hvpnet", vt_model_dir="new")
        forward_net.to(args.device)
        reverse_net = DiffusionModel(args, len(label_list), clstm_path, ner_model_name="hvpnet", vt_model_dir="old")
        reverse_net.to(args.device)
        ddpm_trainer = DDPMTrainer(train_data=train_dataloader_labeled, val_data=val_dataloader_labeled, test_data=test_dataloader_labeled, unlabeled_data=val_dataloader_unlabeled,
                                         forward_net=forward_net, reverse_net=reverse_net, label_map=label_mapping, args=args, logger=logger, writer=writer)
        args.load_path = os.path.join(args.save_path, "best_")
        ddpm_trainer.predict()

if __name__ == "__main__":
    main()